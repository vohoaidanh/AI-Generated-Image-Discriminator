base:
  data_path: D:/K32/do_an_tot_nghiep/image-classification-pytorch/RealFakeDB_tiny
  data_index: null # alternative way to build dataset. check README for more details
  save_path: ./run/experiment # path to save
  device: auto
  random_seed: 0 # set to -1 to disable random seed
  cudnn_deterministic: false # set to True to turn on CUDNN deterministic setting, but it may slow down your training
  overwrite: false # overwrite save_path
  progress: true # real-time metric display, output cannot be redirected
  save_weight_path: weights #location to save .pt file during and after trained
 
data:
  num_classes: &num_classes 2 # number of classes
  input_size: # image size
      - 224
      - 224
  in_channels: 3 # number of image channel
  mean: auto # 'auto' or a list of three numbers for RGB
  std: auto # 'auto' or a list of three numbers for RGB
  sampling_strategy: instance_balanced # instance_balanced / class_balanced / progressively_balanced. ref: https://arxiv.org/abs/1910.09217
  sampling_weights_decay_rate: 0.9 # if sampling_strategy is progressively_balanced, sampling weight will change from class_balanced to instance_balanced
  data_augmentation: # available operations are list in 'data_augmentation_args' below
    - random_crop
    - horizontal_flip
    - vertical_flip
    - color_distortion
    - rotation
    - translation

huggingface: # Training dataset from huggingface
    dataset: HDanh/real_gen_dateset
    split:
        - train
        - test
    classes:
        - fake
        - real

data_augment:
    blur_prob: 0.1
    blur_sig: 
        - 0.0
        - 3.0
    jpg_prob: 0.1
    jpg_method: 
        - cv2
        - pil
    jpg_qual: 
        - 30
        - 100
    loadSize:
        - 224
        - 224
    rz_interp: 
        - bilinear
    

model:
    backbone: resnet18
    num_classes: *num_classes

train:
  network: resnet18 # available networks are list in networks.yaml
  backend: torchvision # network builder backend (timm or torchvision)
  pretrained: true # load weights from pre-trained model training on ImageNet
  checkpoint: null # load weights from other pretrained model
  epochs: &epochs 1
  batch_size: 16
  num_workers: 0 # number of cpus used to load data at each step
  criterion: CrossEntropyLoss # available criterions are list in 'criterion_args' below
  loss_weight: null # null / balance / dynamic / list with shape num_classes. Weights for loss function. Don't use it with weighted sampling!
  loss_weight_decay_rate: 0 # if loss_weights is dynamic, loss weight will decay from balance to equivalent weights
  warmup_epochs: 0 # set to 0 to disable warmup
  metrics: [acc, f1, auc, precision, recall, kappa] # available metrics are list in utils.metrics
  indicator: kappa # indicator for best model selection in validation set
  save_interval: 5 # the epoch interval of saving model
  eval_interval: 1 # the epoch interval of evaluating model on val dataset
  sample_view: false # save and visualize a batch of images on Tensorboard
  pin_memory: false # enables fast data transfer to CUDA-enabled GPUs

eval: # Setting all infor for evaluation
    batch_size: 16
    num_workers: 0 # number of cpus used to load data at each step
    metrics: [acc, f1, auc, precision, recall, kappa] # available metrics are list in utils.metrics
    classes:
        - fake
        - real
    checkpoint: weights/best.pt
    data_path: D:/K32/do_an_tot_nghiep/image-classification-pytorch/RealFakeDB_tiny/val

solver:
  optimizer: SGD # SGD / ADAM / ADAMW
  learning_rate: 0.00001 # initial learning rate
  lr_scheduler: StepLR # available schedulers are list in 'scheduler_args' below. please remember to update scheduler_args when number of epoch changes.
  momentum: 0.9 # only for SGD. set to 0 to disable momentum
  nesterov: true # only for SGD.
  weight_decay: 0.0005 # set to 0 to disable weight decay
  adamw_betas: [0.9, 0.999] # for ADAMW optimizer

criterion_args:
  cross_entropy: {}
  mean_square_error: {}
  mean_absolute_error: {}
  smooth_L1: {}
  kappa_loss: {}
  focal_loss:
    alpha: 5
    reduction: mean
